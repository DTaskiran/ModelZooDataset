{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Abstract\n",
    "This notebook reproduces the benchmark results from Table 2 of the paper, predicting model properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "\n",
    "# set environment variables to limit cpu usage\n",
    "import os\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\"  # export OMP_NUM_THREADS=4\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"4\"  # export OPENBLAS_NUM_THREADS=4\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"6\"  # export MKL_NUM_THREADS=6\n",
    "os.environ[\"VECLIB_MAXIMUM_THREADS\"] = \"4\"  # export VECLIB_MAXIMUM_THREADS=4\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"6\"  # export NUMEXPR_NUM_THREADS=6\n",
    "\n",
    "from checkpoints_to_datasets.dataset_base import ModelDatasetBase\n",
    "\n",
    "from model_definitions.def_baseline_models import (\n",
    "    IdentityModel,\n",
    "    LayerQuintiles,\n",
    ")\n",
    "from model_definitions.def_downstream_module import (\n",
    "    DownstreamTaskLearner,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_compute_benchmarks(dataset_path:Path, index_dict_path:Path):\n",
    "    \"\"\"\n",
    "    input datset_path: pathlib.Path to the preprocessed dataset.pt\n",
    "    input index_dict_path: pathlib.Path to the index dict of the dataset\n",
    "    return; dictionaries with R^2/accuracy for each property on _train, _val, _test splits of the zoo.\n",
    "    \"\"\"\n",
    "    print('try to load dataset from file')\n",
    "    dataset = torch.load(dataset_path)\n",
    "    \n",
    "    trainset = dataset[\"trainset\"]\n",
    "    valset = dataset[\"valset\"]\n",
    "    testset = dataset[\"testset\"]\n",
    "\n",
    "    # index_dict\n",
    "    index_dict = json.load(index_dict_path.open(\"r\"))\n",
    "\n",
    "\n",
    "    # instanciate baseline models\n",
    "    im = IdentityModel()\n",
    "    lq = LayerQuintiles(index_dict)\n",
    "    # instanciate downstream task wrapper\n",
    "    dtl = DownstreamTaskLearner()\n",
    "    #\n",
    "\n",
    "    # weights\n",
    "    results_weights = dtl.eval_dstasks(\n",
    "        model=im, trainset=trainset, testset=testset, valset=valset, batch_size=100\n",
    "    )\n",
    "    # statistics\n",
    "    results_stats = dtl.eval_dstasks(\n",
    "        model=lq, trainset=trainset, testset=testset, valset=valset, batch_size=100\n",
    "    )\n",
    "    return results_weights, results_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download one of the datasets and the corresponding index_dict\n",
    "dataset_path = Path('./path/to/dataset.pt')\n",
    "index_dict_path = Path('./path/to/index_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by calling the load_dataset_compute_benchmarks function, all linear models to predict \n",
    "# all properties in the datasets are fitted and the R^2 / accuracy saved in res_w / res_stats.\n",
    "res_w, res_stats = load_dataset_compute_benchmarks(dataset_path, index_dict_path)\n",
    "print(\"results:\")\n",
    "for key in res_w.keys():\n",
    "    print(f'{key} - weights: {res_w[key]*100:2.1f} - stats: {res_stats[key]*100:2.1f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
